{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "N12-Crawling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bu\n",
    "\n",
    "n_pages = 4 # 2046\n",
    "Time_Date = list()\n",
    "Title = list()\n",
    "Wrote = list()\n",
    "Link = list()\n",
    "\n",
    "\n",
    "for n in range(1, n_pages + 1):\n",
    "  print(n)\n",
    "  url = \"https://www.mako.co.il/news-military?page=\" + str(n)\n",
    "  response = requests.get(url)\n",
    "  soup = bu(response.content, \"html.parser\")\n",
    "  print(response)\n",
    "  print(soup)\n",
    "  uls = soup(\"ul\", attrs={\"class\": \"more-items\"})\n",
    "\n",
    "  for ul in uls:\n",
    "    for li in ul.findAll('li'):\n",
    "      ah = li.p.a\n",
    "      Title.append(ah.text.replace(\"\\n\", \" \"))\n",
    "      Link.append(\"mako.co.il\" + ah.attrs[\"href\"])\n",
    "      spn = li.find_all(\"span\")\n",
    "      try:\n",
    "        Wrote.append(spn[0].text.replace(\"\\n\", \" \"))\n",
    "      except IndexError:\n",
    "        Wrote.append(numpy.NaN)\n",
    "      try:\n",
    "        Time_Date.append(spn[1].text)\n",
    "      except IndexError:\n",
    "        Time_Date.append(numpy.NaN)\n",
    "  print(len(Time_Date), \",\", len(Title), \",\", len(Wrote), \",\", len(Link))\n",
    "\n",
    "df = pd.DataFrame({\"Time_Date\": Time_Date, \"Title\": Title, \"Wrote\": Wrote, \"Link\": Link})\n",
    "df.to_csv('N12-Crawling.csv')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "N12_DataProcessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "\n",
    "\n",
    "df1 = pd.read_csv('**********/N12-Crawling.csv', lineterminator='\\n').copy()\n",
    "\n",
    "df1['Date'] = pd.to_datetime(df1['Time_Date'], dayfirst=True)\n",
    "df1['Year'] = pd.DatetimeIndex(df1['Date']).year\n",
    "df1['Week_Year'] = df1['Date'].dt.strftime(\"%G %V\")\n",
    "df.sort_values(by = ['Date'], inplace = True)\n",
    "\n",
    "Monthdf = df1['Week_Year'].value_counts(sort=False)\n",
    "Monthdf.sort_index(inplace=True)\n",
    "\n",
    "\n",
    "df.drop(df.index[df['Year'] <= 2010], inplace=True)\n",
    "df.dropna(subset = ['Year'], inplace=True)\n",
    "\n",
    "df.to_csv('N12_DaPro.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ta_125_Selenium"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
    "\n",
    "driver = webdriver.Chrome(r\"*********/chromedriver\")\n",
    "driver.get(\"https://il.investing.com/indices/ta100-historical-data\")\n",
    "WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.ID, 'data_interval'))).click()\n",
    "WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.ID, 'widgetFieldDateRange'))).click()\n",
    "date = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.ID, 'startDate')))\n",
    "date.clear()\n",
    "date.send_keys(\"01/01/2011\",Keys.ENTER)\n",
    "time.sleep(3)\n",
    "df_TA125 = pd.read_html(driver.page_source)[0]\n",
    "\n",
    "time.sleep(3)\n",
    "df_TA125.to_csv('TA-125.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ILS_USD_Selenium"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "\n",
    "driver = webdriver.Chrome(r\"************/chromedriver\")\n",
    "\n",
    "\n",
    "driver.get(\"https://il.investing.com/currencies/usd-ils-historical-data\")\n",
    "WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.ID, 'widgetFieldDateRange'))).click()\n",
    "date = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.ID, 'startDate')))\n",
    "date.clear()\n",
    "date.send_keys(\"01/01/2011\",Keys.ENTER)\n",
    "time.sleep(3)\n",
    "df_us = pd.read_html(driver.page_source)[0]\n",
    "\n",
    "time.sleep(3)\n",
    "df_us.to_csv('ILS-USD.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wikipedia Crawling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "import requests\n",
    "import lxml.html as lh\n",
    "\n",
    "\n",
    "url = \"https://he.wikipedia.org/wiki/מבצעי_צבא_הגנה_לישראל\"\n",
    "page = requests.get(url)\n",
    "doc = lh.fromstring(page.content)\n",
    "tr_elements = doc.xpath('//tbody')[15]\n",
    "\n",
    "\n",
    "NameOper = list()\n",
    "PurpOper = list()\n",
    "DateOper = list()\n",
    "for t in tr_elements:\n",
    "    NameOper.append(t[0].text_content().replace(\"\\n\", \"\"))\n",
    "    PurpOper.append(t[1].text_content().replace(\"\\n\", \"\"))\n",
    "    DateOper.append(t[2].text_content().replace(\"\\n\", \"\"))\n",
    "\n",
    "df = pd.DataFrame({'NameOper':NameOper, 'PurpOper':PurpOper, 'DateOper':DateOper})\n",
    "df.to_csv('HiOperIDF.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ILS-USD_DataProcessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_USD = pd.read_csv('*************/ILS-USD.csv', lineterminator='\\n').copy()\n",
    "\n",
    "df_USD = df_USD.rename({'תאריך': 'Date', 'שער': 'Rate', 'פתיחה':'Open', 'גבוה':'High', 'נמוך':'Low', 'שינוי %':'Change %'}, axis=1).copy()\n",
    "\n",
    "df_USD.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "df_USD['Date'] = pd.to_datetime(df_USD['Date'], dayfirst=True)\n",
    "df_USD['Year'] = pd.DatetimeIndex(df_USD['Date']).year\n",
    "df_USD['Week_Year'] = df_USD['Date'].dt.strftime(\"%G %V\")\n",
    "df_USD['Change %'] = df_USD['Change %'].str.rstrip('%').astype('float')\n",
    "\n",
    "df_USD.to_csv('DaPr_USD.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "EDA-USD_Rate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "N12_df = pd.read_csv('************/N12_DaPro.csv', lineterminator='\\n').copy()\n",
    "N12_df['Date'] = pd.to_datetime(N12_df['Time_Date'], dayfirst=True) # Not sure why this is needed again\n",
    "N12_df['Week_Year'] = N12_df['Date'].dt.strftime(\"%G %V\")\n",
    "\n",
    "N12_daily = N12_df['Date'].value_counts(sort=False).rename(\"Daily articles\").copy()\n",
    "N12_daily.sort_index(inplace=True)\n",
    "N12_weekly = N12_df['Week_Year'].value_counts(sort=False).rename(\"Weekly articles\").copy()\n",
    "\n",
    "\n",
    "USD_df = pd.read_csv('***************/ILS-USD.csv', lineterminator='\\n').copy()\n",
    "USD_df = USD_df.rename({'תאריך': 'Date', 'שער': 'Rate', 'פתיחה':'Open', 'גבוה':'High', 'נמוך':'Low', 'שינוי %':'Change %'}, axis=1).copy()\n",
    "USD_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "USD_df['Date'] = pd.to_datetime(USD_df['Date'], dayfirst=True)\n",
    "USD_df['Year'] = pd.DatetimeIndex(USD_df['Date']).year\n",
    "USD_df['Week_Year'] = USD_df['Date'].dt.strftime(\"%G %V\")\n",
    "USD_df.set_index('Date', inplace=True)\n",
    "USD_df['Change %'] = USD_df['Change %'].str.rstrip('%').astype('float')\n",
    "USD_df.drop(USD_df.index[USD_df['Year'] <= 2010], inplace=True)\n",
    "\n",
    "USD_week = USD_df.groupby(['Week_Year']).max()\n",
    "USD_week = pd.concat([USD_week, USD_week['Rate'].pct_change().rename(\"Interweek change\").shift(periods=-1)], axis=1).copy()\n",
    "\n",
    "Weekly_unified_df = pd.concat([USD_week, N12_weekly], axis=1).sort_index()\n",
    "fig, ax = plt.subplots()\n",
    "Weekly_unified_df['Weekly articles'].plot(ax=ax, style='b-', figsize=(15, 10))\n",
    "Weekly_unified_df['High'].plot(ax=ax, style='r-', secondary_y=True)\n",
    "ax.legend([ax.get_lines()[0], ax.right_ax.get_lines()[0]],\\\n",
    "           ['Weekly articles','USD rate'], bbox_to_anchor=(0.9, 0.9))\n",
    "fig.show()\n",
    "\n",
    "print(\"Average ILS/USD rate:\")\n",
    "print(USD_df['Change %'].mean())\n",
    "\n",
    "unified_df = pd.concat([USD_df, N12_daily], axis=1).sort_index().copy()\n",
    "unified_df.to_csv(\"alldataframe.csv\")\n",
    "\n",
    "BigArticlesTLV_df = unified_df[unified_df['Daily articles'] >= 20].copy()\n",
    "print (\"Average TLV 125 change at Insecure Time:\")\n",
    "print(BigArticlesTLV_df['Change %'].mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "EDA_NotDone_OnlyforTestNOw"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from numpy.core.numeric import NaN\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "n12 = pd.read_csv('*************/N12_DaPro.csv', lineterminator='\\n').copy()\n",
    "df_USD = pd.read_csv('***********/DaPr_USD.csv', lineterminator='\\n').copy()\n",
    "\n",
    "\n",
    "#print(n12['Year'].value_counts(sort=False))\n",
    "# # Week_Num_bins = [datetime.strptime(\"0000 0\", \"%Y %V\"), datetime.strptime(\"2008 51\",\"%Y %V\")  ,datetime.strptime(\"2009 3\",\"%Y %V\"), datetime.strptime(\"2012 45\",\"%Y %V\"), datetime.strptime(\"2012 47\",\"%Y %V\"), datetime.strptime(\"2014 22\",\"%Y %V\"), datetime.strptime(\"2014 35\",\"%Y %V\"), datetime.strptime(\"2021 17\",\"%Y %V\"), datetime.strptime(\"2021 20\",\"%Y %V\")]\n",
    "\n",
    "bins = [0, 2011, 2012, 2013, 2014, 2020, 2021] #2008-2009, 2012, 2014, 2021\n",
    "names = [np.NaN, 'Operation Pillar of Defense', np.NaN, 'Operation Protective Edge', np.NaN, 'Israel–Palestine crisis']\n",
    "\n",
    "\n",
    "n12['TimeOfWar'] = pd.cut(n12.Year, bins, labels=names, ordered=False)\n",
    "df_USD['TimeOfWar'] = pd.cut(df_USD.Year, bins, labels=names, ordered=False)\n",
    "\n",
    "print(n12)\n",
    "\n",
    "# df_articles = n12[n12['TimeOfWar'] != np.NaN].copy()\n",
    "# # df_articles = df_articles.dropna(how='any')\n",
    "# plt.figure()\n",
    "# # df_articles = df_articles['Week_Year'].groupby(df_articles['TimeOfWar'])\n",
    "# df_articles['Week_Year'].value_counts(sort=False).plot.bar()\n",
    "# plt.show()\n",
    "# print(df_articles)\n",
    "\n",
    "\n",
    "print(n12['Year'].value_counts(sort=False))\n",
    "plt.figure()\n",
    "n12['Year'].value_counts(sort=False).plot.bar(color=['black', 'red', 'black', 'red', 'black', 'black', 'black', 'black', 'black', 'black', 'red'])\n",
    "\n",
    "plt.title('כמות מאמרים בכל שנה'[::-1])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(n12.info())\n",
    "\n",
    "plt.figure()\n",
    "n12['Year'].groupby(n12['TimeOfWar']).value_counts(sort=False).plot.bar(color=['blue','cyan','blue'])\n",
    "# plt.savefig('/content/drive/MyDrive/visualization/?.png')\n",
    "plt.title('כמות מאמרים בשנים של מבצעים משמעותיים'[::-1])\n",
    "plt.show()\n",
    "\n",
    "# ######################################################\n",
    "df_USD['Year'].groupby(df_USD['TimeOfWar']).value_counts(sort=False)\n",
    "# import seaborn as sns\n",
    "\n",
    "# # left\n",
    "# sns.pairplot(n12, kind=\"scatter\", hue=\"TimeOfWar\", markers=[\"o\", \"s\", \"D\"], palette=\"Set2\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# left\n",
    "sns.pairplot(df_USD, kind=\"scatter\", hue=\"TimeOfWar\", markers=[\"o\", \"s\", \"D\"], palette=\"Set2\")\n",
    "plt.show()\n",
    "\n",
    "# Year_of_war = [2008, 2009, 2012, 2014, 2021]\n",
    "# Name_of_war  = ['Operation Cast Lead', 'Operation Cast Lead', 'Operation Pillar of Defense', 'Operation Protective Edge', 'Israel–Palestine crisis']\n",
    "\n",
    "# df_war = {'Year':Year_of_war, 'Name':Name_of_war}\n",
    "#Amount_of_articles =\n",
    "# n12Year = [n12['Year'].value_counts(sort=False)[0]]\n",
    "# n12Amount = [n12['Year'].value_counts(sort=False)[1]]\n",
    "# df_articles = {'Year':n12Year, 'AmountOfArticles':n12Amount}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "EDA_Ta-125_NotDone"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import numpy\n",
    "\n",
    "#seaborn -> sns.plot -> LM.plot הכי יתאים?\n",
    "\n",
    "N12_df = pd.read_csv('*************/N12_DaPro.csv', lineterminator='\\n').copy()\n",
    "N12_df['Date'] = pd.to_datetime(N12_df['Time_Date'], dayfirst=True) # Not sure why this is needed again\n",
    "N12_df['Week_Year'] = N12_df['Date'].dt.strftime(\"%G %V\")\n",
    "\n",
    "N12_daily = N12_df['Time_Date'].value_counts(sort=False).rename(\"Daily articles\").copy()\n",
    "N12_daily.sort_index(inplace=True)\n",
    "N12_weekly = N12_df['Week_Year'].value_counts(sort=False).rename(\"Weekly articles\").copy()\n",
    "\n",
    "USD_df = pd.read_csv('***************/DaPr_USD.csv', lineterminator='\\n').copy()\n",
    "\n",
    "# USD_df['Date'] = pd.to_datetime(USD_df['Date'], dayfirst=True)\n",
    "# USD_df['Year'] = pd.DatetimeIndex(USD_df['Date']).year\n",
    "# USD_df['Week_Year'] = USD_df['Date'].dt.strftime(\"%G %V\")\n",
    "# USD_df.set_index('Date', inplace=True)\n",
    "# USD_df['Change %'] = USD_df['Change %'].str.rstrip('%').astype('float')\n",
    "\n",
    "# USD_df.drop(USD_df.index[USD_df['Year'] <= 2010], inplace=True)\n",
    "USD_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "print(USD_df.info())\n",
    "USD_df.set_index('Date', inplace=True)\n",
    "\n",
    "USD_week = USD_df.groupby(['Week_Year']).max()\n",
    "USD_week = pd.concat([USD_week, USD_week['Rate'].pct_change().rename(\"Interweek change\").shift(periods=-1)], axis=1).copy()\n",
    "print(USD_week.info())\n",
    "\n",
    "Weekly_unified_df = pd.concat([USD_week, N12_weekly], axis=1).sort_index()\n",
    "\n",
    "Weekly_unified_df.to_csv('/content/drive/MyDrive/datasets/TESTWeekly_unified_df.csv')\n",
    "\n",
    "########################################### \"מנקה את הרעשים\"\n",
    "Weekly_unified_df = Weekly_unified_df.rolling(10).sum()\n",
    "######################## עושה ממוצע על כמה נקודות, כלומר עושה ממוצע בין כל 10 שבועות\n",
    "######################## לסיכום- מחליק את הגרף על תקופה של 10 שבועות\n",
    "fig, ax = plt.subplots()\n",
    "Weekly_unified_df['Weekly articles'].plot(ax=ax, style='b-', figsize=(15, 10))\n",
    "Weekly_unified_df['High'].plot(ax=ax, style='r-', secondary_y=True)\n",
    "ax.legend([ax.get_lines()[0], ax.right_ax.get_lines()[0]],\\\n",
    "           ['Weekly articles','USD rate'], bbox_to_anchor=(0.9, 0.9))\n",
    "\n",
    "################################################################\n",
    "#operations:\n",
    "\n",
    "# #(2008-2009) ###############הורדנו\n",
    "# start_cast_lead = 50 #date(2008, 12, 27)27.12.2008\n",
    "# end_cast_lead = 100 #date(2009, 1, 18)18.1.2009\n",
    "# plt.axvspan(start_cast_lead, end_cast_lead, facecolor='y', alpha=0.3)\n",
    "# ######################################################\n",
    "\n",
    "\n",
    "######################## חישוב\n",
    "# year1, weekofyear1\n",
    "# year2, weekofyear2\n",
    "# (year2-year1)*52+(weekofyear2-weekofyear1)\n",
    "#########################\n",
    "\n",
    "####מלחמה ראשונה מתחילת 2011\n",
    "plt.axvspan(98, 99, facecolor='g', alpha=0.9) #######הסבר בקובץ שלי \"המשך הסבר על הסימונים בגרפים\", חשוב למצגת\n",
    "plt.text(18, 32, 'Pilar Of Defense\\n'+'עמוד ענן'[::-1]+'\\nVictory!') #מ98 לסמן בגרף\n",
    "\n",
    "# plt.axvspan(start_pilar_of_defense,end_pilar_of_defense)\n",
    "# plt.text(start_pilar_of_defense, 200, 'Pilar Of Defense')\n",
    "\n",
    "####מלחמה שניה מתחילת 2011\n",
    "plt.axvspan(179, 186, facecolor='y', alpha=0.5)  #מ179 לסמן בגרף\n",
    "plt.text(100, 32, 'Protective Edge 2014\\n'+'מבצע צוק איתן'[::-1]+'\\nBoth sides claim victory') #######הסבר בקובץ שלי \"המשך הסבר על הסימונים בגרפים\", חשוב למצגת\n",
    "\n",
    "# #7 weeks\n",
    "# plt.axvspan(start_protective_edge_2014,end_protective_edge_2014)\n",
    "# plt.text(start_protective_edge_2014, 170, 'Protective Edge 2014')\n",
    "\n",
    "\n",
    "####מלחמה שלישית מתחילת 2011\n",
    "plt.axvspan(538, 540.1428571428571, facecolor='m', alpha=0.6)\n",
    "# plt.axvspan(start_2021_Israel_Palestine_crisis, end_2021_Israel_Palestine_crisis) להמחשה\n",
    "plt.text(428, 32, '2021 Israel-Palestine Crisis\\n'+'מבצע שומר החומות'[::-1]+'\\nBoth sides claim victory') #קצת לפני איפה שנסמן\n",
    "\n",
    "################################################################################################ אם טוב להמשיך\n",
    "# plt.axvspan(190, 250, facecolor='g', alpha=0.3)\n",
    "# plt.savefig('/content/drive/MyDrive/visualization/Weeklyarticles_high_linear-regression.jpg') #png בלי רקע\n",
    "fig.show()\n",
    "\n",
    "######הוספתי\n",
    "# plt.fig()\n",
    "# ax1 = Weekly_unified_df.plot.scatter(x='Weekly articles', y='High', c='Red')\n",
    "# fig.show()\n",
    "# ##########################\n",
    "\n",
    "\n",
    "\n",
    "#לנסות לתקן אם אפשר\n",
    "\n",
    "\n",
    "# ##########################\n",
    "print(\"Weekly articles_High Correlation:\")\n",
    "print(Weekly_unified_df['Weekly articles'].corr(Weekly_unified_df['High']))\n",
    "##### ערך הקורלציה הינו\n",
    "##### 0.359\n",
    "##### Weekly_unified_df['High'] מה שאומר שיש קורלציה חיובית די נמוכה בין כמות הכתבות פר שבוע לבין ערך\n",
    "##### זה אומר שכשמספר הכתבות גבוה אז ערך המטבע עולה\n",
    "####### זה לא מסתדר עם מה שרצינו להראות?\n",
    "print('value of x(Weekly articles)', Weekly_unified_df['Weekly articles']) #לשם בדיקה\n",
    "print('value type of x(Weekly articles)', type(Weekly_unified_df['Weekly articles'])) #לשם בדיקה\n",
    "#################################################################\n",
    "\n",
    "####################### נבדוק קשר לינארי בין המשתנים\n",
    "x = Weekly_unified_df['High']\n",
    "y = Weekly_unified_df['Weekly articles']\n",
    "# number of observations/points\n",
    "n = np.size(x)\n",
    "\n",
    "# mean of x and y vector\n",
    "m_x = np.mean(Weekly_unified_df['High'])\n",
    "m_y = np.mean(Weekly_unified_df['Weekly articles'])\n",
    "\n",
    "# calculating cross-deviation and deviation about x\n",
    "SS_xy = np.sum(y*x) - n*m_y*m_x\n",
    "SS_xx = np.sum(x*x) - n*m_x*m_x\n",
    "\n",
    "# calculating regression coefficients\n",
    "b_1 = SS_xy / SS_xx\n",
    "b_0 = m_y - b_1*m_x\n",
    "b = b_0, b_1\n",
    "\n",
    "print(\"Estimated coefficients:\\nb_0 = {}  \\\n",
    "          \\nb_1 = {}\".format(b[0], b[1]))\n",
    "\n",
    "###################### plotting regression line\n",
    "\n",
    "# plotting the actual points as scatter plot\n",
    "plt.figure()\n",
    "plt.scatter(x, y, color = \"m\",\n",
    "               marker = \"o\", s = 30)\n",
    "\n",
    "# predicted response vector\n",
    "y_pred = b[0] + b[1]*x\n",
    "# y_pred = -2600 + 85*x\n",
    "# plotting the regression line\n",
    "plt.plot(x, y_pred, color = \"g\")\n",
    "\n",
    "# putting labels\n",
    "plt.xlabel('Weekly articles')\n",
    "plt.ylabel('High')\n",
    "# plt.savefig('/content/drive/MyDrive/visualization/Weeklyarticles_high_linear-regression.jpg') #png בלי רקע\n",
    "# function to show plot\n",
    "fig.show()\n",
    "#########################################################\n",
    "\n",
    " #LOWאז נבדוק איזה קשר לינארי קיים בין כמות כתבות ביטחוניות לערך\n",
    "\n",
    "\n",
    "####################### נבדוק קשר לינארי בין המשתנים\n",
    "x = Weekly_unified_df['Low']\n",
    "y = Weekly_unified_df['Weekly articles']\n",
    "# number of observations/points\n",
    "n = np.size(x)\n",
    "\n",
    "# mean of x and y vector\n",
    "m_x = np.mean(Weekly_unified_df['Low'])\n",
    "m_y = np.mean(Weekly_unified_df['Weekly articles'])\n",
    "\n",
    "# calculating cross-deviation and deviation about x\n",
    "SS_xy = np.sum(y*x) - n*m_y*m_x\n",
    "SS_xx = np.sum(x*x) - n*m_x*m_x\n",
    "\n",
    "# calculating regression coefficients\n",
    "b_1 = SS_xy / SS_xx\n",
    "b_0 = m_y - b_1*m_x\n",
    "b = b_0, b_1\n",
    "\n",
    "print(\"Estimated coefficients:\\nb_0 = {}  \\\n",
    "          \\nb_1 = {}\".format(b[0], b[1]))\n",
    "\n",
    "###################### plotting regression line\n",
    "\n",
    "# plotting the actual points as scatter plot\n",
    "plt.figure()\n",
    "plt.scatter(x, y, color = \"g\",\n",
    "               marker = \"o\", s = 30)\n",
    "\n",
    "# predicted response vector\n",
    "y_pred = b[0] + b[1]*x\n",
    "# y_pred = -2600 + 85*x\n",
    "# plotting the regression line\n",
    "plt.plot(x, y_pred, color = \"r\")\n",
    "\n",
    "# putting labels\n",
    "plt.xlabel('Weekly articles')\n",
    "plt.ylabel('Low')\n",
    "# plt.savefig('/content/drive/MyDrive/visualization/Weeklyarticles_Low_linear-regression.jpg') #png בלי רקע\n",
    "# function to show plot\n",
    "fig.show()\n",
    "########################################################\n",
    "from scipy.stats import chi2_contingency\n",
    "ct = pd.crosstab(Weekly_unified_df['Interweek change'],Weekly_unified_df['Weekly articles'] )\n",
    "print('chi2_contingency:', chi2_contingency(ct))\n",
    "print('chi2_contingency: \\np = chi2_contingency:p-value = 0.2817932103859786 -> p>0.05, השערת הבסיס אינה נדחית')\n",
    "print('ואולי אכן יש קשר בין כמות כתבות ביטחוניות שבועיות המעידות על משבר ביטחוני לבין שינוי בערך המטבע')\n",
    "############################ נבדוק קשר לינארי בין המשתנים\n",
    "x = Weekly_unified_df['Interweek change']\n",
    "y = Weekly_unified_df['Weekly articles']\n",
    "# number of observations/points\n",
    "n = np.size(x)\n",
    "\n",
    "# mean of x and y vector\n",
    "m_x = np.mean(Weekly_unified_df['Interweek change'])\n",
    "m_y = np.mean(Weekly_unified_df['Weekly articles'])\n",
    "\n",
    "# calculating cross-deviation and deviation about x\n",
    "SS_xy = np.sum(y*x) - n*m_y*m_x\n",
    "SS_xx = np.sum(x*x) - n*m_x*m_x\n",
    "\n",
    "# calculating regression coefficients\n",
    "b_1 = SS_xy / SS_xx\n",
    "b_0 = m_y - b_1*m_x\n",
    "b = b_0, b_1\n",
    "\n",
    "print(\"Estimated coefficients:\\nb_0 = {}  \\\n",
    "          \\nb_1 = {}\".format(b[0], b[1]))\n",
    "\n",
    "###################### plotting regression line\n",
    "\n",
    "# plotting the actual points as scatter plot\n",
    "plt.figure()\n",
    "plt.scatter(x, y, color = 'b',\n",
    "               marker = 'o', s = 30)\n",
    "\n",
    "# predicted response vector\n",
    "y_pred = b[0] + b[1]*x\n",
    "# y_pred = -2600 + 85*x\n",
    "# plotting the regression line\n",
    "plt.plot(x, y_pred, color = \"r\")\n",
    "\n",
    "# putting labels\n",
    "plt.xlabel('Weekly articles')\n",
    "plt.ylabel('Interweek change')\n",
    "\n",
    "# function to show plot\n",
    "# plt.savefig('/content/drive/MyDrive/visualization/Weeklyarticles_Interweekchange_linear-regression.jpg') #png בלי רקע\n",
    "fig.show()\n",
    "print(\"Correlation:\")\n",
    "print(Weekly_unified_df['Weekly articles'].corr(Weekly_unified_df['Interweek change']))\n",
    "##############################################################################\n",
    "\n",
    "#####################################################\n",
    "#המשכתי את מה שנתן עשה, לא יודעת למה רלוונטי\n",
    "print (\"Average ILS/USD rate:\")\n",
    "print(USD_df['Change %'].mean())\n",
    "\n",
    "unified_df = pd.concat([USD_df, N12_daily], axis=1).sort_index().copy()\n",
    "\n",
    "BigArticlesTLV_df = unified_df[unified_df['Daily articles'] >= 20].copy()\n",
    "\n",
    "print (\"Average TLV 125 change at Insecure Time:\")\n",
    "avg = BigArticlesTLV_df['Change %'].mean()\n",
    "print(avg)\n",
    "\n",
    "print (\"Standard deviation TLV 125 change at Insecure Time:\")\n",
    "std =  BigArticlesTLV_df['Change %'].std()\n",
    "print(std)\n",
    "\n",
    "# plt.text(x, y, r'Average is {avg}')\n",
    "# plt.text(x, y, r'Standard deviation is {std}') # לערכים של ההיסטוגרמה עליה אנו רוצים לצייר אותם\n",
    "# #להוסיף את הכיתוב בעזרת הפונקציה plt.text\n",
    "# #X ו Y בהתאם לגרף במקומות של\n",
    "plt.figure()\n",
    "plt.text(-1.5, 25, ('Average is {:2f}').format(avg)) #x וy צריך להתאים את\n",
    "plt.text(-1.5, 22, ('Standard deviation is {:2f}').format(std)) # לערכים של ההיסטוגרמה עליה אנו רוצים לצייר אותם\n",
    "plt.hist(BigArticlesTLV_df['Change %'])\n",
    "\n",
    "plt.title('אחוז השינוי בדולר כאשר יש 02 ומעלה מאמרים ביום'[::-1])\n",
    "# plt.xlabel('אחוז השינוי'[::-1])\n",
    "# plt.ylabel('כמות כתבות ליום'[::-1])\n",
    "# plt.savefig('/content/drive/MyDrive/visualization/20OrMore.jpg') #png בלי רקע\n",
    "fig.show()\n",
    "\n",
    "\n",
    "##########################לשאול את נתן איך\n",
    "# between0to5 = BigArticlesTLV_df[BigArticlesTLV_df['Daily articles'] <=5].copy()\n",
    "# avg = between0to5['Change %'].mean()\n",
    "# std =  between0to5['Change %'].std()\n",
    "# plt.figure()\n",
    "# plt.text(-1.5, 25, ('Average is {:2f}').format(avg)) #x וy צריך להתאים את\n",
    "# plt.text(-1.5, 22, ('Standard deviation is {:2f}').format(std)) # לערכים של ההיסטוגרמה עליה אנו רוצים לצייר אותם\n",
    "# plt.hist(between0to5['Change %'])\n",
    "\n",
    "# plt.title('אחוז השינוי בדולר כאשר יש בין 0 ל5 מאמרים ביום'[::-1])\n",
    "# plt.xlabel('אחוז השינוי'[::-1])\n",
    "# plt.ylabel('כמות כתבות ליום'[::-1])\n",
    "# plt.savefig('C:/Users/chen/Desktop/PythonProject/between0to5.jpg') #png בלי רקע\n",
    "# fig.show()\n",
    "\n",
    "####################################################"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "EDA_Unified_BigDataFrame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('************************/TESTWeekly_unified_df.csv', lineterminator='\\n').copy()\n",
    "# Density\n",
    "# sns.pairplot(df, diag_kind=\"kde\")\n",
    "\n",
    "# Histogram\n",
    "# sns.pairplot(df, diag_kind=\"hist\")\n",
    "\n",
    "# You can custom it as a density plot or histogram so see the related sections\n",
    "sns.pairplot(df, diag_kind=\"kde\", diag_kws=dict(shade=True, bw_adjust=.05, vertical=False) )\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "bins = [0, 2011, 2012, 2013, 2014, 2020, 2021] #2008-2009, 2012, 2014, 2021\n",
    "names = [np.NaN, 'Operation Pillar of Defense', np.NaN, 'Operation Protective Edge', np.NaN, 'Israel–Palestine crisis']\n",
    "\n",
    "df['TimeOfWar'] = pd.cut(df.Year, bins, labels=names, ordered=False)\n",
    "\n",
    "# df['Year'].groupby(df['TimeOfWar']).value_counts(sort=False)\n",
    "# left\n",
    "sns.pairplot(df, kind=\"scatter\", hue=\"TimeOfWar\", markers=[\"o\", \"s\", \"D\"], palette=\"Set2\")\n",
    "# plt.savefig('/content/drive/MyDrive/visualization/ערךהשקל-דולרבזמנימלחמהוכתבות.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "df.dropna(how='any', inplace=True)\n",
    "# # set figure size\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "# plot polar axis\n",
    "ax = plt.subplot(111, polar=True)\n",
    "\n",
    "# remove grid\n",
    "plt.axis('off')\n",
    "\n",
    "# Set the coordinates limits\n",
    "upperLimit = 100\n",
    "lowerLimit = 30\n",
    "\n",
    "# Compute max and min in the dataset\n",
    "max = df['Interweek change'].max()\n",
    "\n",
    "# Let's compute heights: they are a conversion of each item value in those new coordinates\n",
    "# In our example, 0 in the dataset will be converted to the lowerLimit (10)\n",
    "# The maximum will be converted to the upperLimit (100)\n",
    "slope = (max - lowerLimit) / max\n",
    "heights = slope * df['Interweek change'] + lowerLimit\n",
    "\n",
    "# Compute the width of each bar. In total we have 2*Pi = 360°\n",
    "width = 2*np.pi / len(df.index)\n",
    "\n",
    "# Compute the angle each bar is centered on:\n",
    "indexes = list(range(1, len(df.index)+1))\n",
    "angles = [element * width for element in indexes]\n",
    "angles\n",
    "\n",
    "# initialize the figure\n",
    "plt.figure(figsize=(20,10))\n",
    "ax = plt.subplot(111, polar=True)\n",
    "plt.axis('off')\n",
    "\n",
    "# Draw bars\n",
    "bars = ax.bar(\n",
    "    x=angles,\n",
    "    height=heights,\n",
    "    width=width,\n",
    "    bottom=lowerLimit,\n",
    "    linewidth=2,\n",
    "    edgecolor=\"white\",\n",
    "    color=['coral', 'blueviolet', 'chocolate' ],#'\"#61a4b2\",\n",
    ")\n",
    "\n",
    "# little space between the bar and the label\n",
    "labelPadding = 4\n",
    "\n",
    "# Add labels\n",
    "for bar, angle, height, label in zip(bars,angles, heights, df[\"TimeOfWar\"]):\n",
    "\n",
    "    # Labels are rotated. Rotation must be specified in degrees :(\n",
    "    rotation = np.rad2deg(angle)\n",
    "\n",
    "    # Flip some labels upside down\n",
    "    alignment = \"\"\n",
    "    if angle >= np.pi/2 and angle < 3*np.pi/2:\n",
    "        alignment = \"right\"\n",
    "        rotation = rotation + 180\n",
    "    else:\n",
    "        alignment = \"left\"\n",
    "\n",
    "    # Finally add the labels\n",
    "    ax.text(\n",
    "        x=angle,\n",
    "        y=lowerLimit + bar.get_height() + labelPadding,\n",
    "        s=label,\n",
    "        ha=alignment,\n",
    "        va='center',\n",
    "        rotation=rotation,\n",
    "        rotation_mode=\"anchor\")\n",
    "###########################################################################"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "EDA_Opertition_Year&Mean"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "wars_d = {'Year':[2011, 2012, 2013, 2014, 2018, 2019, 2021], 'OperationsAmount':[1,1,1,3,1,3,1]}\n",
    "wars_df= pd.DataFrame(wars_d)\n",
    "print(wars_df)\n",
    "# wars_df['OperationsAmount'].groupby(wars_df['Year'])\n",
    "\n",
    "# create data: an array of values\n",
    "size_of_groups=[1,1,1,3,0,0,0,1,3,1]\n",
    "values=[1,1,1,3,1,3,1]\n",
    "names='2011', '2012', '2013', '2014', '2018', '2019', '2021',\n",
    "# Create a pieplot\n",
    "plt.pie(size_of_groups)\n",
    "plt.pie(values, labels=names, labeldistance=1.15)\n",
    "plt.title('  Operations per year 2011-2021',   fontweight =\"bold\")\n",
    "# plt.savefig('/content/drive/MyDrive/visualization/Operationsperyear2011-2021.png'\n",
    "plt.show()\n",
    "###########################################################################\n",
    "print(wars_df.describe())\n",
    "\n",
    "Uni_df = pd.read_csv('****************/TESTWeekly_unified_df.csv', lineterminator='\\n').copy()\n",
    "\n",
    "Uni_df['Weekly articles'].groupby(Uni_df['Year'])\n",
    "# Uni_df.dropna(how='any')#YEARLY_ARTICLES\n",
    "# size_of_groups= [for i in Uni_df['Weekly articles']]\n",
    "# # Create a pieplot\n",
    "# plt.pie(size_of_groups)\n",
    "# # names='2011', '2012', '2013', '2014', '2018', '2019', '2021',\n",
    "# # # plt.pie(Uni_df['Weekly articles'], labels=names, labeldistance=1.15);\n",
    "# # plt.show()\n",
    "###########################################################################\n",
    "bins = [0, 2010, 2011, 2012, 2013, 2014, 2017, 2018, 2019, 2020, 2021] #2008-2009, 2012, 2014, 2021\n",
    "names = [np.NaN, '2011 Single Operation', '2012 Single Operation', '2013 Single Operation', '2014 Three Operations', np.NaN, '2018 Single Operation', '2019 Three Operations', np.NaN, '2021 Single Operation']\n",
    "Uni_df['OperationsAmountPerYear'] = pd.cut(Uni_df.Year, bins, labels=names, ordered=False)\n",
    "\n",
    "Uni_df['OperationsAmountPerYear']= Uni_df['OperationsAmountPerYear'].cat.add_categories('Zero Operations')\n",
    "Uni_df['OperationsAmountPerYear'].fillna('Zero Operations', inplace=True)\n",
    "# Uni_df['OperationsAmountPerYear'] = Uni_df['OperationsAmountPerYear'].fillna('No Operations')\n",
    "# d = Uni_df['Year', 'Interweek change', 'Weekly articles'].groupby(Uni_df['OperationsAmountPerYear']).value_counts(sort=False)#.plot.bar()#color=['blue','cyan','blue'])\n",
    "# d = Uni_df['Year'].groupby(Uni_df['OperationsAmountPerYear'])#.value_counts(sort=False)#.plot.bar()#color=['blue','cyan','blue'])\n",
    "grouped_multiple = Uni_df.groupby(['OperationsAmountPerYear']).agg({'Weekly articles': ['mean', 'min', 'max'], 'Interweek change': ['mean', 'min', 'max']})\n",
    "grouped_multiple.columns = ['Weekly articles_mean', 'Weekly articles_min', 'Weekly articles_max', 'Interweek change_mean', 'Interweek change_min', 'Interweek change_max']\n",
    "grouped_multiple = grouped_multiple.reset_index()\n",
    "print(grouped_multiple)\n",
    "grouped_multiple.to_csv('grouped_multiple_Uni_war_df.csv')\n",
    "# grouped_multiple.plot.bar()\n",
    "# plt.show()\n",
    "# res=gb_sales_demo.reset_index()\n",
    "d_mean = grouped_multiple[[\"OperationsAmountPerYear\",'Weekly articles_mean','Interweek change_mean']].copy()\n",
    "d_mean.to_csv('Mean_grouped_multiple_Uni_war_df.csv')\n",
    "# d_mean = Uni_df.groupby(['OperationsAmountPerYear']).agg({'Weekly articles': ['mean'], 'Interweek change': ['mean']})\n",
    "# res=d_mean.reset_index()\n",
    "print(d_mean)\n",
    "\n",
    "# res = d_mean.reset_index()\n",
    "# print(res)\n",
    "res_wide=d_mean.melt(id_vars=\"OperationsAmountPerYear\")\n",
    "print(res_wide)\n",
    "\n",
    "plt.figure(figsize=(20,16))\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.barplot(x='OperationsAmountPerYear', y=\"value\",data=res_wide, hue=\"variable\",palette='magma')\n",
    "# sns.catplot(x=\"OperationsAmountPerYear\", kind=\"count\", palette=\"ch:.25\")\n",
    "# Uni_df[['Interweek change', 'Weekly articles']].groupby(Uni_df['OperationsAmountPerYear']).value_counts(sort=False).plot.bar()#color=['blue','cyan','blue'])\n",
    "# d['Interweek change', 'Weekly articles']\n",
    "\n",
    "\n",
    "plt.legend(prop ={'size': 10})\n",
    "\n",
    "plt.title('מחולק לפי שנים וכמות אירועים ביטחוניים \\nממוצע כמות כתבות שבועיות וממוצע אחוז שינוי שבועי בשקל-דולר\\n\\n'[::-1],\n",
    "          fontweight =\"bold\")\n",
    "\n",
    "plt.show()\n",
    "d_mean['OperationsAmount'] = [1,1,1,3,1,3,1,0]\n",
    "d_mean['Year'] = [2011, 2012, 2013, 2014, 2018, 2019, 2021, np.NAN]\n",
    "grid = sns.JointGrid(x='OperationsAmount', y='Weekly articles_mean', data=d_mean)\n",
    "\n",
    "g = grid.plot_joint(sns.scatterplot, hue='Interweek change_mean', data=d_mean)\n",
    "sns.kdeplot(d_mean.loc[d_mean['Interweek change_mean']>0, 'OperationsAmount'], ax=g.ax_marg_x, legend=False)\n",
    "sns.kdeplot(d_mean.loc[d_mean['Interweek change_mean']>0, 'OperationsAmount'], ax=g.ax_marg_x, legend=False)\n",
    "sns.kdeplot(d_mean.loc[d_mean['Interweek change_mean']<0, 'Weekly articles_mean'], ax=g.ax_marg_y, vertical=True, legend=False)\n",
    "sns.kdeplot(d_mean.loc[d_mean['Interweek change_mean']<0, 'Weekly articles_mean'], ax=g.ax_marg_y, vertical=True, legend=False)\n",
    "\n",
    "print(d_mean)\n",
    "#################################????\n",
    "pd.crosstab(d_mean['Weekly articles_mean'],d_mean.OperationsAmount).plot(kind='bar')\n",
    "print('\\n\\n\\n')\n",
    "pd.crosstab(d_mean['Interweek change_mean'],d_mean.OperationsAmount).plot(kind='bar')\n",
    "pd.crosstab(d_mean.OperationsAmount,d_mean['Interweek change_mean']).plot(kind='line')\n",
    "################################???\n",
    "\n",
    "\n",
    "# Use the 'hue' argument to provide a factor variable\n",
    "sns.lmplot( x=\"Weekly articles_mean\", y=\"Interweek change_mean\", data=d_mean, fit_reg=False, hue='OperationsAmount', legend=False)\n",
    "\n",
    "# Move the legend to an empty part of the plot\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()\n",
    "# Use the 'hue' argument to provide a factor variable\n",
    "sns.lmplot( x=\"Weekly articles_mean\", y=\"Interweek change_mean\", data=d_mean, fit_reg=True, hue='OperationsAmount', legend=False)\n",
    "\n",
    "# Move the legend to an empty part of the plot\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('משמע בין השנים 2014-2019 \\nניתן לראות את הקשר בין עלייה בכמות כתבות ביטחוניות ועליה בערך השקל-דולר כאשר אירעו 3 אירועים ביטחוניים בשנה\\n\\n'[::-1],\n",
    "          fontweight =\"bold\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Use the 'hue' argument to provide a factor variable\n",
    "sns.lmplot( x='Year', y=\"Interweek change_mean\", data=d_mean, fit_reg=False, hue='OperationsAmount', legend=False)\n",
    "\n",
    "# # Move the legend to an empty part of the plot\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Use the 'hue' argument to provide a factor variable\n",
    "sns.lmplot( x='Year', y=\"Interweek change_mean\", data=d_mean, fit_reg=True, hue='OperationsAmount', legend=False)\n",
    "\n",
    "# # Move the legend to an empty part of the plot\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()\n",
    "# # Use the 'hue' argument to provide a factor variable\n",
    "# sns.lmplot( x=\"Weekly articles_mean\", y=\"Interweek change_mean\", data=d_mean, fit_reg=True, hue='OperationsAmount', legend=False)\n",
    "\n",
    "# # Move the legend to an empty part of the plot\n",
    "# plt.legend(loc='lower right')\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# Use the 'hue' argument to provide a factor variable\n",
    "sns.lmplot( x='OperationsAmount', y=\"Interweek change_mean\", data=d_mean, fit_reg=True, legend=False)\n",
    "\n",
    "# # Move the legend to an empty part of the plot\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Use the 'hue' argument to provide a factor variable\n",
    "sns.lmplot( x='OperationsAmount', y=\"Interweek change_mean\", data=d_mean, fit_reg=True,hue='Year', legend=False)\n",
    "\n",
    "# # Move the legend to an empty part of the plot\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}